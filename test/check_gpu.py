#!/usr/bin/env python3
"""
æ£€æŸ¥GPUæ”¯æŒæƒ…å†µ
"""

def check_gpu_support():
    print("ğŸ” æ£€æŸ¥GPUæ”¯æŒæƒ…å†µ...")
    print("=" * 50)
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        print("âœ… PyTorch å·²å®‰è£…")
        print(f"   CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDA è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
        else:
            print("   âŒ CUDA ä¸å¯ç”¨")
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
    
    print()
    
    # æ£€æŸ¥ONNX Runtime
    try:
        import onnxruntime as ort
        print("âœ… ONNX Runtime å·²å®‰è£…")
        providers = ort.get_available_providers()
        print("   å¯ç”¨æ‰§è¡Œæä¾›ç¨‹åº:")
        for provider in providers:
            print(f"     - {provider}")
        
        if 'CUDAExecutionProvider' in providers:
            print("   âœ… CUDA æ‰§è¡Œæä¾›ç¨‹åºå¯ç”¨")
        else:
            print("   âŒ CUDA æ‰§è¡Œæä¾›ç¨‹åºä¸å¯ç”¨")
            
        if 'DmlExecutionProvider' in providers:
            print("   âœ… DirectML æ‰§è¡Œæä¾›ç¨‹åºå¯ç”¨ (Windows GPU)")
        else:
            print("   âŒ DirectML æ‰§è¡Œæä¾›ç¨‹åºä¸å¯ç”¨")
            
    except ImportError:
        print("âŒ ONNX Runtime æœªå®‰è£…")
    
    print()
    
    # æ£€æŸ¥CUDAç‰ˆæœ¬
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA GPU é©±åŠ¨å·²å®‰è£…")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'CUDA Version' in line:
                    print(f"   {line.strip()}")
        else:
            print("âŒ NVIDIA GPU é©±åŠ¨æœªå®‰è£…æˆ–ä¸å¯ç”¨")
    except FileNotFoundError:
        print("âŒ nvidia-smi å‘½ä»¤ä¸å¯ç”¨")
    
    print()
    print("=" * 50)
    print("ğŸ’¡ å¯ç”¨GPUåŠ é€Ÿçš„å»ºè®®:")
    print("1. å®‰è£… onnxruntime-gpu: pip install onnxruntime-gpu")
    print("2. å®‰è£… PyTorch CUDA ç‰ˆæœ¬: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("3. ç¡®ä¿ NVIDIA é©±åŠ¨å’Œ CUDA å·²æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    check_gpu_support()
