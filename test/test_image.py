#!/usr/bin/env python3
"""
å›¾ç‰‡OCRæµ‹è¯•ç¨‹åº
æ”¯æŒä¼ å…¥å›¾ç‰‡è·¯å¾„ï¼Œè¿›è¡ŒOCRè¯†åˆ«å¹¶ç»Ÿè®¡é€Ÿåº¦
"""

import cv2
import os
import sys
import time
import argparse
import json
from pathlib import Path
from ocr import OCR


def test_single_image(image_path, output_dir="output", save_visualization=True):
    """æµ‹è¯•å•å¼ å›¾ç‰‡çš„OCRè¯†åˆ«"""
    
    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–OCR
    print("ğŸ”„ åˆå§‹åŒ–OCR...")
    try:
        ocr = OCR()
        print("âœ… OCRåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
        return None
    
    # è¯»å–å›¾ç‰‡
    print(f"ğŸ“– è¯»å–å›¾ç‰‡: {image_path}")
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None
    
    print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
    
    # æ‰§è¡ŒOCRè¯†åˆ«
    print("ğŸ” å¼€å§‹OCRè¯†åˆ«...")
    start_time = time.time()
    
    try:
        result = ocr(image)
        end_time = time.time()
        process_time = end_time - start_time
        print(f"âœ… OCRè¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {process_time:.3f}ç§’")
    except Exception as e:
        print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
        return None
    
    # è§£æç»“æœ
    texts = []
    for i, (bbox, (text, score)) in enumerate(result):
        texts.append({
            'id': i + 1,
            'text': text,
            'confidence': float(score),
            'bbox': bbox
        })
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'image_path': image_path,
        'image_size': f"{image.shape[1]}x{image.shape[0]}",
        'text_count': len(texts),
        'process_time': process_time,
        'speed': f"{len(texts)/process_time:.1f} æ–‡æœ¬/ç§’" if process_time > 0 else "0 æ–‡æœ¬/ç§’",
        'texts': texts
    }
    
    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š è¯†åˆ«ç»“æœç»Ÿè®¡:")
    print(f"   æ–‡æœ¬æ•°é‡: {stats['text_count']}")
    print(f"   å¤„ç†æ—¶é—´: {stats['process_time']:.3f}ç§’")
    print(f"   è¯†åˆ«é€Ÿåº¦: {stats['speed']}")
    
    print(f"\nğŸ“ è¯†åˆ«åˆ°çš„æ–‡æœ¬:")
    print("-" * 60)
    for text_info in texts:
        print(f"{text_info['id']:2d}. {text_info['text']} (ç½®ä¿¡åº¦: {text_info['confidence']:.3f})")
    
    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    if save_visualization:
        print(f"\nğŸ¨ ä¿å­˜å¯è§†åŒ–ç»“æœ...")
        result_image = image.copy()
        
        for text_info in texts:
            bbox = text_info['bbox']
            text = text_info['text']
            score = text_info['confidence']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            pts = np.array(bbox, np.int32)
            cv2.polylines(result_image, [pts], True, (0, 255, 0), 2)
            
            # æ·»åŠ æ–‡æœ¬æ ‡ç­¾
            x, y = int(bbox[0][0]), int(bbox[0][1])
            label = f"{text[:15]}... ({score:.2f})" if len(text) > 15 else f"{text} ({score:.2f})"
            cv2.putText(result_image, label, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # ä¿å­˜å¯è§†åŒ–å›¾ç‰‡
        output_image_path = os.path.join(output_dir, f"{Path(image_path).stem}_result.jpg")
        cv2.imwrite(output_image_path, result_image)
        print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_image_path}")
    
    # ä¿å­˜JSONç»“æœ
    json_path = os.path.join(output_dir, f"{Path(image_path).stem}_result.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSONç»“æœå·²ä¿å­˜: {json_path}")
    
    return stats


def test_multiple_images(image_paths, output_dir="output", save_visualization=True):
    """æµ‹è¯•å¤šå¼ å›¾ç‰‡çš„OCRè¯†åˆ«"""
    
    print(f"ğŸ”„ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(image_paths)} å¼ å›¾ç‰‡...")
    
    # åˆå§‹åŒ–OCR
    print("ğŸ”„ åˆå§‹åŒ–OCR...")
    try:
        ocr = OCR()
        print("âœ… OCRåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    results = []
    total_time = 0
    total_texts = 0
    
    for i, image_path in enumerate(image_paths):
        print(f"\n{'='*60}")
        print(f"ğŸ“· å¤„ç†ç¬¬ {i+1}/{len(image_paths)} å¼ å›¾ç‰‡: {os.path.basename(image_path)}")
        
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
        if not os.path.exists(image_path):
            print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            continue
        
        # è¯»å–å›¾ç‰‡
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
            continue
        
        print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
        
        # æ‰§è¡ŒOCRè¯†åˆ«
        start_time = time.time()
        try:
            result = ocr(image)
            end_time = time.time()
            process_time = end_time - start_time
            total_time += process_time
            
            # è§£æç»“æœ
            texts = []
            for j, (bbox, (text, score)) in enumerate(result):
                texts.append({
                    'id': j + 1,
                    'text': text,
                    'confidence': float(score),
                    'bbox': bbox
                })
            
            total_texts += len(texts)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'image_path': image_path,
                'image_size': f"{image.shape[1]}x{image.shape[0]}",
                'text_count': len(texts),
                'process_time': process_time,
                'speed': f"{len(texts)/process_time:.1f} æ–‡æœ¬/ç§’" if process_time > 0 else "0 æ–‡æœ¬/ç§’",
                'texts': texts
            }
            
            results.append(stats)
            
            print(f"âœ… è¯†åˆ«å®Œæˆ: {len(texts)} ä¸ªæ–‡æœ¬, è€—æ—¶: {process_time:.3f}ç§’")
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            if save_visualization:
                result_image = image.copy()
                for text_info in texts:
                    bbox = text_info['bbox']
                    text = text_info['text']
                    score = text_info['confidence']
                    
                    pts = np.array(bbox, np.int32)
                    cv2.polylines(result_image, [pts], True, (0, 255, 0), 2)
                    
                    x, y = int(bbox[0][0]), int(bbox[0][1])
                    label = f"{text[:15]}... ({score:.2f})" if len(text) > 15 else f"{text} ({score:.2f})"
                    cv2.putText(result_image, label, (x, y-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                
                output_image_path = os.path.join(output_dir, f"{Path(image_path).stem}_result.jpg")
                cv2.imwrite(output_image_path, result_image)
            
        except Exception as e:
            print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
            continue
    
    # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ‰¹é‡æµ‹è¯•å®Œæˆ!")
    print(f"   å¤„ç†å›¾ç‰‡: {len(results)}/{len(image_paths)}")
    print(f"   æ€»æ–‡æœ¬æ•°: {total_texts}")
    print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"   å¹³å‡é€Ÿåº¦: {total_texts/total_time:.1f} æ–‡æœ¬/ç§’" if total_time > 0 else "0 æ–‡æœ¬/ç§’")
    print(f"   å¹³å‡æ¯å¼ : {total_time/len(results):.3f}ç§’" if len(results) > 0 else "0ç§’")
    
    # ä¿å­˜æ‰¹é‡ç»“æœ
    batch_result = {
        'total_images': len(image_paths),
        'processed_images': len(results),
        'total_texts': total_texts,
        'total_time': total_time,
        'average_speed': f"{total_texts/total_time:.1f} æ–‡æœ¬/ç§’" if total_time > 0 else "0 æ–‡æœ¬/ç§’",
        'average_per_image': f"{total_time/len(results):.3f}ç§’" if len(results) > 0 else "0ç§’",
        'results': results
    }
    
    batch_json_path = os.path.join(output_dir, "batch_results.json")
    with open(batch_json_path, 'w', encoding='utf-8') as f:
        json.dump(batch_result, f, ensure_ascii=False, indent=2)
    print(f"âœ… æ‰¹é‡ç»“æœå·²ä¿å­˜: {batch_json_path}")
    
    return batch_result


def main():
    parser = argparse.ArgumentParser(description="å›¾ç‰‡OCRæµ‹è¯•ç¨‹åº")
    parser.add_argument('images', nargs='+', help='å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒå¤šå¼ å›¾ç‰‡ï¼‰')
    parser.add_argument('--output', '-o', default='output', help='è¾“å‡ºç›®å½• (é»˜è®¤: output)')
    parser.add_argument('--no-viz', action='store_true', help='ä¸ä¿å­˜å¯è§†åŒ–ç»“æœ')
    
    args = parser.parse_args()
    
    print("ğŸš€ OCRå›¾ç‰‡æµ‹è¯•ç¨‹åº")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_dir = "models"
    required_files = ["det.onnx", "rec.onnx", "ocr.res"]
    
    print("ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    missing_files = []
    for file in required_files:
        file_path = os.path.join(model_dir, file)
        if os.path.exists(file_path):
            print(f"   âœ… {file}")
        else:
            print(f"   âŒ {file} ç¼ºå¤±")
            missing_files.append(file)
    
    if missing_files:
        print(f"\nâŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {missing_files}")
        print("è¯·å…ˆè¿è¡Œ: python download_models.py")
        return
    
    # å¤„ç†å›¾ç‰‡
    if len(args.images) == 1:
        # å•å¼ å›¾ç‰‡
        result = test_single_image(
            args.images[0], 
            args.output, 
            not args.no_viz
        )
    else:
        # å¤šå¼ å›¾ç‰‡
        result = test_multiple_images(
            args.images, 
            args.output, 
            not args.no_viz
        )
    
    if result:
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! ç»“æœä¿å­˜åœ¨: {args.output}")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥!")


if __name__ == "__main__":
    import numpy as np
    main()
